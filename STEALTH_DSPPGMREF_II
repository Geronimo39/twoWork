import pyodbc
import pandas as pd

# ---------- Mapping: Objekttypen (WHOBJ) ----------
OBJTYPE_MAP = {
    "P": "PROGRAM",
    "F": "FILE",
    "D": "DEVICE",
}

# ---------- Mapping: Usage Codes (WHFUSG) ----------
# Hinweis: je nach IBM i / DSPPGMREF-Version können Codes variieren.
# Unbekannte Codes bleiben als "USG_<code>" erhalten.
USAGE_MAP = {
    0: "UNKNOWN",
    1: "INPUT",           # read
    2: "OUTPUT",          # write
    3: "UPDATE",
    4: "INPUT_UPDATE",
    5: "DELETE",
    6: "INPUT_DELETE",    # selten / je nach System
    7: "OUTPUT_UPDATE",   # selten / je nach System
    8: "OPEN",
    9: "CLOSE",
    10: "REFERENCE",      # je nach System
    11: "EXECUTE",        # je nach System
}


def _first_existing(cols_upper, *candidates):
    """
    Liefert den ersten Spaltennamen aus candidates, der in cols_upper existiert.
    cols_upper: dict {upper_name: original_name}
    """
    for c in candidates:
        cu = c.upper()
        if cu in cols_upper:
            return cols_upper[cu]
    return None


def get_dspgmref(
    target_lib: str,
    system_name: str,
    user: str,
    pwd: str,
    outfile_lib: str = "QTEMP",
    outfile: str = "PGMREFS",
    include_objtypes=("P", "F", "D"),
) -> pd.DataFrame:
    """
    Führt DSPPGMREF aus und liefert normalisierte Referenzen zurück.

    Normalisiertes Schema (Spalten im Return-DF):
    - caller_pgm
    - caller_lib (falls verfügbar)
    - target_obj
    - target_lib (falls verfügbar)
    - target_objtype_code   (P/F/D/...)
    - target_objtype        (PROGRAM/FILE/DEVICE/...)
    - usage_code            (int, falls parsebar)
    - usage                 (INPUT/OUTPUT/UPDATE/...)
    """

    conn_str = f"DRIVER={{IBM i Access ODBC Driver}};SYSTEM={system_name};UID={user};PWD={pwd};"
    conn = pyodbc.connect(conn_str, autocommit=True)
    cur = conn.cursor()

    # DSPPGMREF Ziel: Bibliothek/Programme
    # Hinweis: Du kannst auch PGM(*ALL/*ALL) übergeben, wenn du "alles" willst.
    cmd = f"DSPPGMREF PGM({target_lib}/*ALL) OUTPUT(*OUTFILE) OUTFILE({outfile_lib}/{outfile}) OUTMBR(*FIRST *REPLACE)"

    try:
        cur.execute(f"CALL QSYS2.QCMDEXC('{cmd}')")

        # 1) Spalten der Outfile-Tabelle ermitteln (robust gegen Release-Unterschiede)
        colinfo = pd.read_sql(f"SELECT * FROM {outfile_lib}.{outfile} FETCH FIRST 1 ROWS ONLY", conn)
        cols_upper = {c.upper(): c for c in colinfo.columns}

        # 2) Relevante Spalten finden (Fallback-Kaskaden)
        # Caller (Programm, das referenziert)
        c_caller = _first_existing(cols_upper, "WHPNAM", "WHPPGM", "WHPRGM", "PROGRAM", "PGM")
        c_callerlib = _first_existing(cols_upper, "WHPLIB", "WHLIBP", "PROGRAM_LIBRARY", "PGMLIB")

        # Target (Objekt, das referenziert wird)
        c_target = _first_existing(cols_upper, "WHFNAM", "WHAFNAM", "WHTNAM", "OBJECT", "OBJ")
        c_targetlib = _first_existing(cols_upper, "WHFLIB", "WHALIB", "WHTLIB", "OBJECT_LIBRARY", "OBJLIB")

        # Objekttyp (P/F/D)
        c_objtype = _first_existing(cols_upper, "WHOBJ", "WHOTYP", "WHOBJT", "OBJTYPE", "TYPE")

        # Usage
        c_usage = _first_existing(cols_upper, "WHFUSG", "WHUSG", "USAGE", "USG")

        missing = [name for name, col in [
            ("caller", c_caller),
            ("target", c_target),
            ("objtype", c_objtype),
        ] if col is None]

        if missing:
            raise RuntimeError(
                "PGMREFS Outfile hat nicht die erwarteten Spalten. "
                f"Fehlend: {missing}. Gefundene Spalten: {list(colinfo.columns)}"
            )

        # 3) Daten lesen (nur relevante Spalten)
        select_cols = [c_caller, c_target, c_objtype]
        if c_usage:
            select_cols.append(c_usage)
        if c_callerlib:
            select_cols.append(c_callerlib)
        if c_targetlib:
            select_cols.append(c_targetlib)

        sql = f"SELECT {', '.join(select_cols)} FROM {outfile_lib}.{outfile}"
        raw = pd.read_sql(sql, conn)

    finally:
        conn.close()

    # 4) Normalisieren: einheitliche Spaltennamen
    df = pd.DataFrame()
    df["caller_pgm"] = raw[c_caller].astype(str)
    df["target_obj"] = raw[c_target].astype(str)
    df["target_objtype_code"] = raw[c_objtype].astype(str)

    if c_callerlib:
        df["caller_lib"] = raw[c_callerlib].astype(str)
    else:
        df["caller_lib"] = None

    if c_targetlib:
        df["target_lib"] = raw[c_targetlib].astype(str)
    else:
        df["target_lib"] = None

    if c_usage:
        # usage_code als int, wenn möglich
        df["usage_code"] = pd.to_numeric(raw[c_usage], errors="coerce").astype("Int64")
    else:
        df["usage_code"] = pd.Series([pd.NA] * len(df), dtype="Int64")

    # 5) Trim/Upper (wichtig bei IBM i)
    for col in ["caller_pgm", "caller_lib", "target_obj", "target_lib", "target_objtype_code"]:
        df[col] = df[col].fillna("").astype(str).str.strip().str.upper()
        df.loc[df[col] == "", col] = pd.NA

    df["target_objtype"] = df["target_objtype_code"].map(OBJTYPE_MAP).fillna(df["target_objtype_code"])

    # Usage mapping
    def _map_usage(x):
        if pd.isna(x):
            return "UNKNOWN"
        x_int = int(x)
        return USAGE_MAP.get(x_int, f"USG_{x_int}")

    df["usage"] = df["usage_code"].apply(_map_usage)

    # 6) Optional: Filter auf gewünschte Objekttypen
    if include_objtypes:
        include_objtypes = tuple([s.upper() for s in include_objtypes])
        df = df[df["target_objtype_code"].isin(include_objtypes)].copy()

    # 7) (Optional) Praktische Schlüsselspalten für spätere Graphen
    # Für Visualisierungen ist "LIB/OBJ" oft besser als nur OBJ.
    df["caller_full"] = (df["caller_lib"].fillna("?") + "/" + df["caller_pgm"].fillna("?")).where(
        df["caller_pgm"].notna(), pd.NA
    )
    df["target_full"] = (df["target_lib"].fillna("?") + "/" + df["target_obj"].fillna("?")).where(
        df["target_obj"].notna(), pd.NA
    )

    # 8) Leichen entfernen (falls Outfile Sonderzeilen enthält)
    df = df.dropna(subset=["caller_pgm", "target_obj", "target_objtype_code"]).reset_index(drop=True)

    return df


#####   testing  ########
df = get_dspgmref(
    target_lib="GDV",
    system_name=SYSTEM_NAME,
    user=USER,
    pwd=PWD,
    include_objtypes=("P", "F", "D"),
)

print(df.head(20))
print(df["target_objtype_code"].value_counts(dropna=False))
print(df["usage"].value_counts(dropna=False).head(20))

